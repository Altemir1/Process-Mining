{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOpS2XLZt+R5XwB+/jvRlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Altemir1/Process-Mining/blob/main/Predictive_Business_Process_Monitoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you have to consider, when you split an event log into train and test sets for training and\n",
        "testing a prediction model?\n",
        "\n",
        "1. **Data Handling Perspective**: Each trace should remain intact. Traces must be divided into either training or testing sets, not split in the middle. This ensures we respect trace independence and avoid data leakage.\n",
        "\n",
        "2. **Deployment Perspective**: In production, predictions are made from partial traces (prefixes), not full ones. Therefore, during training, we simulate this by generating prefixes of varying lengths and labeling them with the trace outcome (OK or NOK). This mirrors how the model will be used in real scenarios."
      ],
      "metadata": {
        "id": "pTFV17ARWFaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading train event logs"
      ],
      "metadata": {
        "id": "AVwGaPojY6E2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVJLhi0KVwYa",
        "outputId": "eb1afe1a-3312-4b8b-ebee-e6e70d6ff9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'C', 'D', 'C', 'D', 'J', 'H'] -> OK\n",
            "['A', 'C', 'D', 'J', 'H', 'B'] -> NOK\n",
            "['A', 'B', 'B', 'B', 'J', 'H', 'B', 'J', 'H'] -> OK\n",
            "['A', 'C', 'D', 'C', 'D', 'B', 'B', 'J', 'H', 'C', 'D', 'B', 'E', 'F', 'G', 'I', 'C', 'D'] -> NOK\n",
            "['A', 'B', 'E', 'F', 'G', 'F', 'I', 'B', 'B', 'E', 'F', 'G', 'F', 'F', 'F', 'F', 'I'] -> OK\n"
          ]
        }
      ],
      "source": [
        "def load_traces_with_labels(filepath):\n",
        "    traces = []\n",
        "    labels = []\n",
        "\n",
        "    with open(filepath, \"r\") as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 2:\n",
        "                continue  # Skip if line is too short\n",
        "            *trace, label = parts  # All but last = trace, last = label\n",
        "            traces.append(trace)\n",
        "            labels.append(label)\n",
        "\n",
        "    return traces, labels\n",
        "\n",
        "train_file = \"/content/train.txt\"  # Make sure this is the correct path\n",
        "traces, labels = load_traces_with_labels(train_file)\n",
        "\n",
        "# Show first 5 traces and labels\n",
        "for trace, label in zip(traces[:5], labels[:5]):\n",
        "    print(trace, \"->\", label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation of prefixes"
      ],
      "metadata": {
        "id": "vniggcerZV_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prefixes(traces, labels, min_prefix_length=1):\n",
        "    prefix_traces = []\n",
        "    prefix_labels = []\n",
        "\n",
        "    for trace, label in zip(traces, labels):\n",
        "        for i in range(min_prefix_length, len(trace) + 1):\n",
        "            prefix = trace[:i]\n",
        "            prefix_traces.append(prefix)\n",
        "            prefix_labels.append(label)\n",
        "\n",
        "    return prefix_traces, prefix_labels\n",
        "\n",
        "# Generate prefixes\n",
        "prefix_traces, prefix_labels = generate_prefixes(traces, labels)\n",
        "\n",
        "# Print some examples\n",
        "for t, l in zip(prefix_traces[:5], prefix_labels[:5]):\n",
        "    print(t, \"->\", l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq9I_yGJZL_w",
        "outputId": "19d04e26-0c08-4eea-aaf7-19806c7db594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A'] -> OK\n",
            "['A', 'C'] -> OK\n",
            "['A', 'C', 'D'] -> OK\n",
            "['A', 'C', 'D', 'C'] -> OK\n",
            "['A', 'C', 'D', 'C', 'D'] -> OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize prefixe"
      ],
      "metadata": {
        "id": "6GENo894ZwpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert each prefix list into a space-joined string\n",
        "def flatten_traces(traces):\n",
        "    return [' '.join(trace) for trace in traces]\n",
        "\n",
        "# Flatten for training\n",
        "X_train_text = flatten_traces(prefix_traces)\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", ngram_range=(1, 2))\n",
        "X_train = vectorizer.fit_transform(X_train_text)"
      ],
      "metadata": {
        "id": "IAplKMayZzoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check vectorization results"
      ],
      "metadata": {
        "id": "1_0-4tEwa5zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)  # (1244, n_features)\n",
        "print(vectorizer.get_feature_names_out()[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-urUOjkaKza",
        "outputId": "3e34b2a6-5be4-4c37-d3e4-0c7afe1ede74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1244, 33)\n",
            "['a' 'a b' 'a c' 'b' 'b b' 'b c' 'b e' 'b j' 'c' 'c d']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "y_train = [1 if label == 'OK' else 0 for label in prefix_labels]\n",
        "# Reuse y_train from earlier\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_tr, y_tr)\n",
        "y_pred_xgb = model.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_pred_xgb)\n",
        "print(\"XGBoost Validation Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4hubvdAaLmg",
        "outputId": "031088dd-e621-43c3-ec36-d56455292df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:41:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Validation Accuracy: 0.7630522088353414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalutaion on dev dataset"
      ],
      "metadata": {
        "id": "QyjBGuL1boft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dev.txt with labels\n",
        "def load_labeled_traces(filepath):\n",
        "    traces = []\n",
        "    labels = []\n",
        "    with open(filepath, \"r\") as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            *trace, label = parts\n",
        "            traces.append(trace)\n",
        "            labels.append(label)\n",
        "    return traces, labels\n",
        "\n",
        "# Flatten traces into text format for vectorization\n",
        "def flatten_traces(traces):\n",
        "    return [' '.join(trace) for trace in traces if len(trace) > 0]\n",
        "\n",
        "# Load and preprocess dev.txt\n",
        "dev_traces, dev_labels = load_labeled_traces(\"dev.txt\")\n",
        "dev_text = flatten_traces(dev_traces)\n",
        "X_dev = vectorizer.transform(dev_text)  # same vectorizer used for train\n",
        "\n",
        "# Predict using best model from random search\n",
        "y_pred = model.predict(X_dev)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "y_true = [1 if label == 'OK' else 0 for label in dev_labels]\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(\"Dev Set Accuracy (No Prefix Length):\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riX-5tEne7SK",
        "outputId": "159cf8ae-610c-46cc-bef5-f263b3efa75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev Set Accuracy (No Prefix Length): 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on full data"
      ],
      "metadata": {
        "id": "qmuhUVfzOw0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Load train.txt and dev.txt\n",
        "def load_labeled_traces(filepath):\n",
        "    traces = []\n",
        "    labels = []\n",
        "    with open(filepath, \"r\") as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            *trace, label = parts\n",
        "            traces.append(trace)\n",
        "            labels.append(label)\n",
        "    return traces, labels\n",
        "\n",
        "train_traces, train_labels = load_labeled_traces(\"train.txt\")\n",
        "dev_traces, dev_labels = load_labeled_traces(\"dev.txt\")\n",
        "\n",
        "# Combine train + dev\n",
        "all_traces = train_traces + dev_traces\n",
        "all_labels = train_labels + dev_labels\n",
        "\n",
        "# 2. Flatten traces\n",
        "def flatten_traces(traces):\n",
        "    return [' '.join(trace) for trace in traces if len(trace) > 0]\n",
        "\n",
        "X_text = flatten_traces(all_traces)\n",
        "y_full = [1 if label == 'OK' else 0 for label in all_labels]\n",
        "\n",
        "# 3. Vectorize\n",
        "X_all = vectorizer.fit_transform(X_text)  # reuse or re-fit the best vectorizer\n",
        "\n",
        "# 4. Train best model on full data\n",
        "model.fit(X_all, y_full)\n",
        "\n",
        "# 5. Load test prefixes (no labels)\n",
        "def load_unlabeled_traces(filepath):\n",
        "    traces = []\n",
        "    with open(filepath, \"r\") as file:\n",
        "        for line in file:\n",
        "            trace = line.strip().split()\n",
        "            traces.append(trace)\n",
        "    return traces\n",
        "\n",
        "test_traces = load_unlabeled_traces(\"test_prefixes_no_labels.txt\")\n",
        "X_test_text = flatten_traces(test_traces)\n",
        "X_test = vectorizer.transform(X_test_text)\n",
        "\n",
        "# 6. Predict on test set\n",
        "y_test_pred = model.predict(X_test)\n",
        "label_test_pred = ['OK' if pred == 1 else 'NOK' for pred in y_test_pred]\n",
        "\n",
        "# 7. Save predictions to file\n",
        "with open(\"test_predictions.txt\", \"w\") as f:\n",
        "    for label in label_test_pred:\n",
        "        f.write(label + \"\\n\")\n",
        "\n",
        "print(\"test_predictions.txt created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6nCYKXMO9JA",
        "outputId": "42658b71-423a-40d3-ac13-b8a5f550c97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_predictions.txt created successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:43:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    }
  ]
}